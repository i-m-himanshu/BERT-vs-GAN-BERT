{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i-m-himanshu/BERT-vs-GAN-BERT/blob/main/GAN-BERT/GAN_implementation4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCiEdpQu8Zc7"
      },
      "source": [
        "#Experimental Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btd5HSgD1OVs",
        "outputId": "509e58f7-38d3-49d4-fc9c-12d7c560cb7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'labeled_data_size': 350, 'unlabeld_data_size': 350, 'num_train_epochs': 10}\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# training dataset\n",
        "labeled_data_size = 350 #this was initially 100\n",
        "unlabeled_data_size = 350 #this was initially 100\n",
        "\n",
        "# training hyperparameter\n",
        "num_train_epochs = 10\n",
        "\n",
        "# dict_settings\n",
        "dict_settings = {\n",
        "    'labeled_data_size':labeled_data_size,\n",
        "    'unlabeld_data_size':unlabeled_data_size,\n",
        "    'num_train_epochs':num_train_epochs\n",
        "}\n",
        "\n",
        "print(dict_settings)\n",
        "\n",
        "entire_notebook_t0 = time.time()#??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7XCKprt9AZG"
      },
      "source": [
        "#Using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR8YQSxG1fDU",
        "outputId": "537c3765-1085-4eee-da07-a5d2ddbc0b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "/device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCF1-Dzy2RJk",
        "outputId": "263718c0-c6fe-4b2b-a3cf-10d878004b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#The assert keyword is used when debugging code. The assert keyword lets you test if a condition in your code returns True, if not, the program will raise an AssertionError.\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Tell torch to use GPU\n",
        "device = torch.device(\"cuda\")\n",
        "print('Running GPU: {}'.format(torch.cuda.get_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2iuD-VeW4Rx"
      },
      "outputs": [],
      "source": [
        "# import essential modules\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import math\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EAxL2U5XCCT",
        "outputId": "28724ffa-3a7b-4458-b2b7-b736b86dfef9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7efd400e3ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Set random seed\n",
        "#The seed value is a base value used by a pseudo-random generator to produce random numbers.\n",
        "seed = 1\n",
        "\n",
        "#The random number or data generated by Python's random module is not truly random; it is pseudo-random(it is PRNG), i.e., deterministic. The random module uses the seed value as a base to generate a random number.\n",
        "#By setting the custom seed value, we can reproduce the data given by a pseudo-random number generator. Choose the same elements from the list randomly every time using random.seed()\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-iHpNJx9Qxl"
      },
      "source": [
        "#Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqik8Oe1OK-"
      },
      "source": [
        "Matplotlib vs Seaborn\n",
        "1.   Matplotlib: It is a Python library used for plotting graphs with the help of other libraries like Numpy and Pandas. It is a powerful tool for visualizing data in Python. It is used for creating statical interferences and plotting 2D graphs of arrays.\n",
        "2.   Seaborn: It is also a Python library used for plotting graphs with the help of Matplotlib, Pandas, and Numpy. It is built on the roof of Matplotlib and is considered as a superset of the Matplotlib library. It helps in visualizing univariate and bivariate data. It uses beautiful themes for decorating Matplotlib graphics. It acts as an important tool in picturing Linear Regression Models. It eliminates the overlapping of graphs and also aids in their beautification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "Y-S5_j7QXIB7",
        "outputId": "276810b7-bbba-4dbd-97a1-fffab337faa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different classes: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efccbe7fe90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Load training dataset\n",
        "df = pd.read_csv('Dataset4_train(ganbert)2.csv')\n",
        "\n",
        "# Mapping the class to label code\n",
        "# Label Encdoing: Label Encoding refers to converting the labels into a numeric form so as to convert them into the machine-readable form. Machine learning algorithms can then decide in a better way how those labels must be operated. It is an important pre-processing step for the structured dataset in supervised learning.\n",
        "class_map={'UNK':0, 'neutral':1, 'sadness':2, 'fear':3, 'anger':4, 'joy':5}\n",
        "\n",
        "# Show number of different classes\n",
        "n_classes = len(class_map)\n",
        "print('Number of different classes: {}'.format(n_classes))\n",
        "\n",
        "# Mapping the class names\n",
        "#'review' and 'sentiment' are two columns names present in our dataset\n",
        "df[\"label\"] = df[\"label\"].map(class_map)\n",
        "\n",
        "# Show class countplot\n",
        "import seaborn as sns\n",
        "sns.countplot(df[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjruli71sJIv",
        "outputId": "5ece7fae-d092-4a52-9721-88ae6a41dd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "1818   maybe if I sold my car now , I wouldn't be so...      1\n",
            "2257                                              oh .       1\n",
            "3812   I had the same feeling when I first came to w...      1\n",
            "2850             Thirty minutes in gym at lunch time .       1\n",
            "2795                                      How was it ?       1\n",
            "...                                                 ...    ...\n",
            "3245                                        Go ahead .       1\n",
            "3235  It is high time you have a talk with him . Tha...      1\n",
            "2602   It was nice to see you , too.And please give ...      1\n",
            "1245                                            What ?       1\n",
            "3797                                       All right .       1\n",
            "\n",
            "[350 rows x 2 columns]\n",
            "                                                   text  label\n",
            "1818   maybe if I sold my car now , I wouldn't be so...      1\n",
            "2257                                              oh .       1\n",
            "3812   I had the same feeling when I first came to w...      1\n",
            "2850             Thirty minutes in gym at lunch time .       1\n",
            "2795                                      How was it ?       1\n",
            "...                                                 ...    ...\n",
            "2824                     When I had my first boyfriend.      5\n",
            "3681  Our only elder sister got married and started ...      5\n",
            "3253                   When my boyfriend and I made up.      5\n",
            "1659               Did you see Ally Mabel last night ?       5\n",
            "2275  I didn't like my former fob and felt joy when ...      5\n",
            "\n",
            "[1750 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Initalize the first df\n",
        "#We have already defined the labeled_data_size=100 at the start\n",
        "df_sampled = df[df['label']==1].sample(labeled_data_size) #We are initializing df_sampled with the 100 data enteries corresponding to sentiment 1 i.e. extremely positive\n",
        "\n",
        "print(df_sampled) #It will print 100 data enteries corresponding to sentiment 1\n",
        "\n",
        "# Import samples from the other classes\n",
        "for i in range(2,6):\n",
        "    df_temp = df[df['label'] == i].sample(labeled_data_size)\n",
        "    df_sampled = pd.concat((df_sampled, df_temp))\n",
        "\n",
        "print(df_sampled) #It will print 100 data enteries corresponding to each sentiment from 1 to 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32GNc-FW5c73",
        "outputId": "f3157904-bf21-45c7-96c4-132ee51438af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data entries: 1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0db47d6bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Show class countplo\n",
        "print('Number of data entries: {}'.format(len(df_sampled)))\n",
        "sns.countplot(df_sampled['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV4WAfhy5rhs",
        "outputId": "1499aff1-bd52-452a-d5ce-e41214bf09d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text label\n",
            "296                                          See you .    UNK\n",
            "1372  Tutorial again !  A fearful feeling came to me...   UNK\n",
            "324   Our only elder sister got married and started ...   UNK\n",
            "2993  When, for example, I was in my eleventh school...   UNK\n",
            "3198  Tabitha Campbell-Black was livid because she w...   UNK\n",
            "...                                                 ...   ...\n",
            "2792                          When my grandmother died.   UNK\n",
            "1711                                             Yes .    UNK\n",
            "2003                                             Jim !    UNK\n",
            "3095   Well , yes . Several colleagues from differen...   UNK\n",
            "1168    Again , I do apologize for the inconvenience .    UNK\n",
            "\n",
            "[350 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Randomly choose 100 data entries which will be converted into unlabled data\n",
        "df_unlabeled = df.sample(unlabeled_data_size)\n",
        "\n",
        "# Convert class to UNK\n",
        "df_unlabeled['label'] = 'UNK'\n",
        "\n",
        "print(df_unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMlydonJ6UCK",
        "outputId": "a0c7ec69-429e-4a65-9d4f-b8e1af6c0004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 2)\n",
            "(350, 2)\n",
            "(350, 2)\n"
          ]
        }
      ],
      "source": [
        "# Split 20% of data from the df_sample as val_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_labeled, df_val = train_test_split(df_sampled,\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=1,\n",
        "                                    stratify=df_sampled['label'])\n",
        "\n",
        "for item in df_labeled, df_unlabeled, df_val:\n",
        "    print(item.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTW10nHV7mfm"
      },
      "outputs": [],
      "source": [
        "! pip install transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVlrz9wU9jc2"
      },
      "source": [
        "#Import BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfnD8nA66jQu",
        "outputId": "8cf475ff-f5cf-4cec-b4cb-cce33486e596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Load BERT tokenizer\n",
        "transformer = BertModel.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxwrQAYv9uhz"
      },
      "source": [
        "#Prepare Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVPjcQd1_9qe",
        "outputId": "0f2cf672-4b74-43c9-876b-a1b4f9d62948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'df_val label mask')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Combine df_labeled and df_unlabeled into the train_dataloader\n",
        "df_train = pd.concat((df_labeled, df_unlabeled))\n",
        "\n",
        "# Convert UNK to class zero\n",
        "df_train['label'] = df_train['label'].apply(lambda x: 0 if x=='UNK' else x)\n",
        "\n",
        "# Create a new column for label_mask\n",
        "def generate_label_mask(label):\n",
        "    if label == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "df_train['label_mask'] = df_train['label'].apply(generate_label_mask)\n",
        "\n",
        "#The subplot() function takes three arguments that describes the layout of the figure.The layout is organized in rows and columns, which are represented by the first and second argument.The third argument represents the index of the current plot.\n",
        "\n",
        "# Show label_mask distribution\n",
        "import matplotlib.pyplot as plt\n",
        "plt.subplot(1,2,1) #the figure has 1 row, 2 columns, and this plot is the first plot.\n",
        "sns.countplot(df_train['label_mask'])\n",
        "plt.title('df_train label mask')\n",
        "\n",
        "# Generate label mask for df_val\n",
        "df_val['label_mask'] = df_val['label'].apply(generate_label_mask)\n",
        "\n",
        "# Show label_mask distribution\n",
        "plt.subplot(1,2,2) #the figure has 1 row, 2 columns, and this plot is the second plot.\n",
        "sns.countplot(df_val['label_mask'])\n",
        "plt.title('df_val label mask')\n",
        "#1 row means the row with the name 'count' and 2 column means the columns with names 'df_train label mask' and 'df_val label mask' in the plot below\n",
        "#if we want a figure with 2 rows an 1 column (meaning that the two plots will be displayed on top of each other instead of side-by-side), we can write the syntax like this:\n",
        "#plt.subplot(2, 1, 1) and plt.subplot(2,1,2) respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSOSGwCJAe0U"
      },
      "outputs": [],
      "source": [
        "# Hyperparameteres\n",
        "max_length = 128\n",
        "batch_size = 32\n",
        "\n",
        "# Tokenization and covnert dataframes to datasets\n",
        "#A DataFrame is a Dataset organized into named columns\n",
        "def encode_df(df):\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    texts = df['text'].values\n",
        "    labels = df['label'].values\n",
        "    label_masks = df['label_mask'].values\n",
        "    \n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(text,\n",
        "                                             add_special_tokens=True,\n",
        "                                             padding='max_length',\n",
        "                                             return_attention_mask=True,\n",
        "                                             max_length=max_length,\n",
        "                                             return_tensors='pt',\n",
        "                                             truncation=True)\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_mask.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "    return input_ids, attention_mask, labels, label_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oam9697rAra_"
      },
      "outputs": [],
      "source": [
        "# Concat input_ds and attention_mask\n",
        "def concat_data(input_ids, attention_mask, labels, label_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_mask = torch.cat(attention_mask, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    label_masks = torch.tensor(label_masks)\n",
        "    \n",
        "    return input_ids, attention_mask, labels, label_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLRv2PL7Awrq"
      },
      "outputs": [],
      "source": [
        "# Convert encoded data to dataset\n",
        "def make_dataloader(input_ids, attention_mask, labels, label_masks, random_sampler=True):\n",
        "    temp_dataset = TensorDataset(input_ids, attention_mask, labels, label_masks)\n",
        "    \n",
        "    if random_sampler:\n",
        "        dataloader = DataLoader(temp_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                sampler=RandomSampler(temp_dataset))\n",
        "\n",
        "    else:\n",
        "        dataloader = DataLoader(temp_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                sampler=SequentialSampler(temp_dataset))\n",
        "    \n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Er8OvLgA1eH"
      },
      "outputs": [],
      "source": [
        "# Convert df_labeled, df_unlabeled, df_val to dataloader\n",
        "\n",
        "#df_labeled\n",
        "input_ids, attention_mask, labels, label_masks = encode_df(df_train)\n",
        "input_ids, attention_mask, labels, label_masks = concat_data(input_ids, attention_mask, labels, label_masks)\n",
        "train_dataloader = make_dataloader(input_ids, attention_mask, labels, label_masks, random_sampler=True)\n",
        "\n",
        "#df_val\n",
        "input_ids, attention_mask, labels, label_masks = encode_df(df_val)\n",
        "input_ids, attention_mask, labels, label_masks = concat_data(input_ids, attention_mask, labels, label_masks)\n",
        "test_dataloader = make_dataloader(input_ids, attention_mask, labels, label_masks, random_sampler=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZPZuEJz96xe"
      },
      "source": [
        "#Set up the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVsnMt0ZJCGU"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "noise_size = 100\n",
        "drate = 0.2\n",
        "\n",
        "# Replicate labeled data to balance poorly represented datasets, \n",
        "# e.g., less than 1% of labeled material\n",
        "#apply_balance = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGOzlwQjJPbJ"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module, Linear, LeakyReLU, Dropout, Sequential, Softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        hidden_sizes = [noise_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output_rep = self.layers(noise)\n",
        "        return output_rep\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
        "        layers = []\n",
        "        hidden_sizes = [input_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "        \n",
        "        self.layers = nn.Sequential(*layers) #per il flatten\n",
        "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "    \n",
        "    def forward(self, input_rep):\n",
        "        input_rep = self.input_dropout(input_rep)\n",
        "        last_rep = self.layers(input_rep)\n",
        "        logits = self.logit(last_rep)\n",
        "        probs = self.softmax(logits)\n",
        "        return last_rep, logits, probs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eztl2hClJ6X_"
      },
      "outputs": [],
      "source": [
        "# Model configuraiton\n",
        "from transformers import BertConfig\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "\n",
        "# Get BERT's hidden size\n",
        "hidden_size = int(config.hidden_size)\n",
        "\n",
        "# Setup hidden_levels\n",
        "hidden_levels = [hidden_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHbYiMmjKDtr"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "n_class = len(df_train['label'].unique())\n",
        "\n",
        "# Initialize the models\n",
        "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels, dropout_rate=drate)\n",
        "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels, num_labels=n_class, dropout_rate=drate)\n",
        "\n",
        "# Move models to GPU\n",
        "for model in transformer,generator,discriminator:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpSK3geuKSiA"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch6SM2D2KRYJ"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuxM6nHjKnVm"
      },
      "outputs": [],
      "source": [
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# Models' variables\n",
        "t_vars = [i for i in transformer.parameters()]\n",
        "d_vars = t_vars + [i for i in discriminator.parameters()]\n",
        "g_vars = [i for i in generator.parameters()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmydidK6KsPW"
      },
      "outputs": [],
      "source": [
        "# Set up optimizers\n",
        "from torch.optim import AdamW\n",
        "lr = 5e-5\n",
        "\n",
        "d_optimizer = AdamW(d_vars, lr=lr)\n",
        "g_optimizer = AdamW(g_vars, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBNHS-jRKwvh"
      },
      "outputs": [],
      "source": [
        "# Schedule\n",
        "apply_scheduler = False\n",
        "warmup_proportion = 0.1\n",
        "\n",
        "# Print\n",
        "print_each_n_step = 10\n",
        "\n",
        "if apply_scheduler:\n",
        "    num_train_examples = len(train_examples)\n",
        "    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "    scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)\n",
        "    scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjs695f3K17H",
        "outputId": "cc5636ea-4be6-4ebd-bcf3-118cf4246871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:10.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:20.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:30.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:40.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:51.\n",
            "\n",
            "  Average training loss generetor: 0.607\n",
            "  Average training loss discriminator: 2.460\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.680\n",
            "  Test Loss: 0.997\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.731\n",
            "  Average training loss discriminator: 1.440\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.734\n",
            "  Test Loss: 0.765\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.729\n",
            "  Average training loss discriminator: 1.083\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.769\n",
            "  Test Loss: 0.731\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:33.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.721\n",
            "  Average training loss discriminator: 0.909\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.783\n",
            "  Test Loss: 0.796\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.717\n",
            "  Average training loss discriminator: 0.813\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.777\n",
            "  Test Loss: 0.858\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.713\n",
            "  Average training loss discriminator: 0.793\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.780\n",
            "  Test Loss: 0.874\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.710\n",
            "  Average training loss discriminator: 0.759\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.803\n",
            "  Test Loss: 0.834\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.708\n",
            "  Average training loss discriminator: 0.772\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.777\n",
            "  Test Loss: 0.992\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.709\n",
            "  Average training loss discriminator: 0.814\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.783\n",
            "  Test Loss: 0.963\n",
            "  Test took: 0:00:03\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     55.    Elapsed: 0:00:11.\n",
            "  Batch    20  of     55.    Elapsed: 0:00:22.\n",
            "  Batch    30  of     55.    Elapsed: 0:00:32.\n",
            "  Batch    40  of     55.    Elapsed: 0:00:43.\n",
            "  Batch    50  of     55.    Elapsed: 0:00:54.\n",
            "\n",
            "  Average training loss generetor: 0.704\n",
            "  Average training loss discriminator: 0.773\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.786\n",
            "  Test Loss: 1.006\n",
            "  Test took: 0:00:03\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "training_stats = []\n",
        "epsilon = 1e-8\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "#models parameters\n",
        "transformer_vars = [i for i in transformer.parameters()]\n",
        "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
        "g_vars = [v for v in generator.parameters()]\n",
        "\n",
        "#optimizer\n",
        "lr = 5e-5\n",
        "dis_optimizer = torch.optim.AdamW(d_vars, lr=lr)\n",
        "gen_optimizer = torch.optim.AdamW(g_vars, lr=lr) \n",
        "\n",
        "#scheduler\n",
        "if apply_scheduler:\n",
        "    num_train_examples = len(train_examples)\n",
        "    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "    scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)\n",
        "    scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, num_train_epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    tr_g_loss = 0\n",
        "    tr_d_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    transformer.train() \n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every print_each_n_step batches.\n",
        "        if step % print_each_n_step == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_label_mask = batch[3].to(device)\n",
        "     \n",
        "        # Encode real data in the Transformer\n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "        \n",
        "        # Generate fake data that should have the same distribution of the ones\n",
        "        # encoded by the transformer. \n",
        "        # First noisy input are used in input to the Generator\n",
        "        noise = torch.zeros(b_input_ids.shape[0],noise_size, device=device).uniform_(0, 1)\n",
        "        # Gnerate Fake data\n",
        "        gen_rep = generator(noise)\n",
        "\n",
        "        # Generate the output of the Discriminator for real and fake data.\n",
        "        # First, we put together the output of the tranformer and the generator\n",
        "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
        "        # Then, we select the output of the disciminator\n",
        "        features, logits, probs = discriminator(disciminator_input)\n",
        "\n",
        "        # Finally, we separate the discriminator's output for the real and fake\n",
        "        # data\n",
        "        split_size = int(features.shape[0]/2)\n",
        "        features_list = torch.split(features, split_size)\n",
        "        D_real_features = features_list[0]\n",
        "        D_fake_features = features_list[1]\n",
        "      \n",
        "        logits_list = torch.split(logits, split_size)\n",
        "        D_real_logits = logits_list[0]\n",
        "        D_fake_logits = logits_list[1]\n",
        "        \n",
        "        probs_list = torch.split(probs, split_size)\n",
        "        D_real_probs = probs_list[0]\n",
        "        D_fake_probs = probs_list[1]\n",
        "\n",
        "        #---------------------------------\n",
        "        #  LOSS evaluation\n",
        "        #---------------------------------\n",
        "        # Generator's LOSS estimation\n",
        "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
        "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
        "        g_loss = g_loss_d + g_feat_reg\n",
        "  \n",
        "        # Disciminator's LOSS estimation\n",
        "        logits = D_real_logits[:,0:-1]\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # The discriminator provides an output for labeled and unlabeled real data\n",
        "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
        "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(class_map))\n",
        "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
        "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.type(torch.bool).to(device))\n",
        "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
        "\n",
        "        # It may be the case that a batch does not contain labeled examples, \n",
        "        # so the \"supervised loss\" in this case is not evaluated\n",
        "        if labeled_example_count == 0:\n",
        "            D_L_Supervised = 0\n",
        "        else:\n",
        "            D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
        "                 \n",
        "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
        "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
        "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
        "\n",
        "        #---------------------------------\n",
        "        #  OPTIMIZATION\n",
        "        #---------------------------------\n",
        "        # Avoid gradient accumulation\n",
        "        gen_optimizer.zero_grad()\n",
        "        dis_optimizer.zero_grad()\n",
        "\n",
        "        # Calculate weigth updates\n",
        "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
        "        g_loss.backward(retain_graph=True)\n",
        "        d_loss.backward() \n",
        "        \n",
        "        # Apply modifications\n",
        "        gen_optimizer.step()\n",
        "        dis_optimizer.step()\n",
        "\n",
        "        # A detail log of the individual losses\n",
        "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
        "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
        "        #             g_loss_d, g_feat_reg))\n",
        "\n",
        "        # Save the losses to print them later\n",
        "        tr_g_loss += g_loss.item()\n",
        "        tr_d_loss += d_loss.item()\n",
        "\n",
        "        # Update the learning rate with the scheduler\n",
        "        if apply_scheduler:\n",
        "            scheduler_d.step()\n",
        "            scheduler_g.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
        "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
        "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #     TEST ON THE EVALUATION DATASET\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our test set.\n",
        "    print(\"\")\n",
        "    print(\"Running Test...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    transformer.eval() #maybe redundant\n",
        "    discriminator.eval()\n",
        "    generator.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_test_accuracy = 0\n",
        "   \n",
        "    total_test_loss = 0\n",
        "    nb_test_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels_ids = []\n",
        "\n",
        "    #loss\n",
        "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in test_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_states = model_outputs[-1]\n",
        "            _, logits, probs = discriminator(hidden_states)\n",
        "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
        "            filtered_logits = logits[:,0:-1]\n",
        "            # Accumulate the test loss.\n",
        "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
        "            \n",
        "        # Accumulate the predictions and the input labels\n",
        "        _, preds = torch.max(filtered_logits, 1)\n",
        "        all_preds += preds.detach().cpu()\n",
        "        all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    all_preds = torch.stack(all_preds).numpy()\n",
        "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    avg_test_loss = avg_test_loss.item()\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    test_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
        "    print(\"  Test took: {:}\".format(test_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss generator': avg_train_loss_g,\n",
        "            'Training Loss discriminator': avg_train_loss_d,\n",
        "            'Valid. Loss': avg_test_loss,\n",
        "            'Valid. Accur.': test_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Test Time': test_time\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOymXdSsNJV7",
        "outputId": "2c7682e1-c6ce-4b7e-874e-66d237c41a89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0db62bfa50>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Training loss\n",
        "ls_g_loss = []\n",
        "ls_d_loss = []\n",
        "ls_val_loss = []\n",
        "ls_val_acc = []\n",
        "\n",
        "for i in range(len(training_stats)):\n",
        "    ls_g_loss.append(training_stats[i]['Training Loss generator'])\n",
        "    ls_d_loss.append(training_stats[i]['Training Loss discriminator'])\n",
        "    ls_val_loss.append(training_stats[i]['Valid. Loss'])\n",
        "    ls_val_acc.append(training_stats[i]['Valid. Accur.'])\n",
        "    \n",
        "#Plotting\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(ls_g_loss, label='g_loss')\n",
        "plt.plot(ls_d_loss, label='d_loss')\n",
        "plt.legend(loc='upper right')\n",
        "         \n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(ls_val_loss, label='val_loss')\n",
        "plt.plot(ls_val_acc, label='val_acc', color='red', linestyle='--')\n",
        "plt.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwjG5gqAOBXc"
      },
      "source": [
        "# Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ALO7NhAWvHt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "d64HXAHANnzy",
        "outputId": "c5bd1d85-6aa4-4c3a-9c1e-872d92f4ac08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data entries: 1300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label  label_mask\n",
              "82     You can't do that ! You can't charge me for a...      4           1\n",
              "1053  ` I 'm so happy you could make it , my favouri...      5           1\n",
              "306                                        Who is he ?       1           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45e7e0de-5258-4e23-af4f-303c8098155f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>You can't do that ! You can't charge me for a...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>` I 'm so happy you could make it , my favouri...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Who is he ?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45e7e0de-5258-4e23-af4f-303c8098155f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45e7e0de-5258-4e23-af4f-303c8098155f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45e7e0de-5258-4e23-af4f-303c8098155f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Load test dataset\n",
        "df_target = pd.read_csv('Dataset4_test(ganbert)2.csv')\n",
        "#df.columns = ['text', 'label']\n",
        "\n",
        "# Show number of data entries\n",
        "print('Number of data entries: {}'.format(len(df_target)))\n",
        "\n",
        "# Mapping label to number\n",
        "df_target['label'] = df_target['label'].map(class_map)\n",
        "\n",
        "# label_mask\n",
        "df_target['label_mask'] = df_target['label'].apply(generate_label_mask)\n",
        "\n",
        "# Show a few samples\n",
        "df_target.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-46xTiSLvDP"
      },
      "outputs": [],
      "source": [
        "# Convert df_target to dataloader\n",
        "#t0 = time.time()\n",
        "\n",
        "input_ids, attention_mask, labels, label_masks = encode_df(df_target)\n",
        "input_ids, attention_mask, labels, label_masks = concat_data(input_ids, attention_mask, labels, label_masks)\n",
        "target_dataloader = make_dataloader(input_ids, attention_mask, labels, label_masks, random_sampler=False)\n",
        "\n",
        "#print('Tokenization took time: {}'.format(format_time(time.time()-t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_zOhKTCNN0b",
        "outputId": "0dbbf4d1-91b5-483d-8f99-dabfa82ec88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Prediction...\n",
            "  Accuracy: 0.752\n",
            "  Test Loss: 1.209\n",
            "  Test took: 0:00:10\n",
            "Show experimental settings: {'labeled_data_size': 350, 'unlabeld_data_size': 350, 'num_train_epochs': 10}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_stats = []\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Prediction...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Set models to eval mode\n",
        "transformer.eval() \n",
        "discriminator.eval()\n",
        "generator.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_pred_accuracy = 0\n",
        "total_pred_loss = 0\n",
        "\n",
        "all_preds = []\n",
        "all_labels_ids = []\n",
        "\n",
        "#loss\n",
        "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in target_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():        \n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "        _, logits, probs = discriminator(hidden_states)\n",
        "        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
        "        filtered_logits = logits[:,0:-1]\n",
        "        # Accumulate the test loss.\n",
        "        total_pred_loss += nll_loss(filtered_logits, b_labels)\n",
        "\n",
        "    # Accumulate the predictions and the input labels\n",
        "    _, preds = torch.max(filtered_logits, 1)\n",
        "    all_preds += preds.detach().cpu()\n",
        "    all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "all_preds = torch.stack(all_preds).numpy()\n",
        "all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "pred_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "print(\"  Accuracy: {0:.3f}\".format(pred_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_pred_loss = total_pred_loss / len(target_dataloader)\n",
        "avg_pred_loss = avg_pred_loss.item()\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "pred_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.3f}\".format(avg_pred_loss))\n",
        "print(\"  Test took: {:}\".format(pred_time))\n",
        "\n",
        "# Record all statistics from this epoch.\n",
        "print('Show experimental settings: {}'.format(dict_settings))\n",
        "print('\\n')\n",
        "\n",
        "prediction_stats.append(\n",
        "    {\n",
        "        'Prediction. Loss': avg_pred_loss,\n",
        "        'prediction. Accur.': pred_accuracy,\n",
        "        'Prediction Time': pred_time,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnd8DVbrNkYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "891813d9-5369-4fcb-ca3f-92a054255c17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0db52ef3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_preds, all_labels_ids)\n",
        "\n",
        "sns.heatmap(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BnPZNwLNrue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7c06ab-7634-4bea-9d08-2e01d8eae720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.69      0.86      0.77       216\n",
            "           2       0.73      0.81      0.77       235\n",
            "           3       0.85      0.68      0.75       297\n",
            "           4       0.62      0.78      0.69       207\n",
            "           5       0.87      0.69      0.77       345\n",
            "\n",
            "    accuracy                           0.75      1300\n",
            "   macro avg       0.75      0.76      0.75      1300\n",
            "weighted avg       0.77      0.75      0.75      1300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report\n",
        "cr = classification_report(all_preds, all_labels_ids)\n",
        "\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGhXgUXSN7Jt"
      },
      "source": [
        "# Time took for the entire noteobok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAQbCUEHNzN7"
      },
      "outputs": [],
      "source": [
        "time_diff = entire_notebook_t0 - time.time()\n",
        "print('Time took for the entire notebook: {}'.format(time_diff))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SCiEdpQu8Zc7",
        "s7XCKprt9AZG",
        "gVlrz9wU9jc2",
        "NxwrQAYv9uhz",
        "tZPZuEJz96xe",
        "MpSK3geuKSiA",
        "fwjG5gqAOBXc",
        "sGhXgUXSN7Jt"
      ],
      "name": "GAN-implementation4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}